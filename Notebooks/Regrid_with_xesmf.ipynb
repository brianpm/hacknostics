{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regrid with xesmf\n",
    "\n",
    "This Notebook shows a bare-bones example of using xesmf to do regridding. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import platform  # only for getting python version number\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# auxilliary stuff\n",
    "import colorcet as cc\n",
    "import esmlab\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from numba import jit\n",
    "# USE AS: @jit(nopython=True)\n",
    "\n",
    "import xesmf as xe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERA-Interim climatology\n",
    "\n",
    "This is grabbing the monthly climatology used by the AMWG diagnostics. \n",
    "\n",
    "The path shows that I mounted CGD's `project` directory on my Mac. Otherwise this should work if you're on CGD systems and using a recent version of xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_erai():\n",
    "    obs_stem = Path(\"/Volumes/project/amp/amwg/amwg_diagnostics/obs_data\")\n",
    "    # NOTE: Is there documentation about these derived data? In particular, no notes on years/sample-size included.\n",
    "    monthly_fils = sorted(list(obs_stem.glob('ERAI_[0-1][0-9]_climo.nc')))\n",
    "    ds = xr.open_mfdataset(monthly_fils, combine='nested', concat_dim='time', decode_times=False)\n",
    "    # the times are mangled, so just use values\n",
    "    ds['time'].values = np.linspace(1,12,12,dtype=int)\n",
    "    ds = ds.transpose('time', 'lev', 'lat', 'lon')\n",
    "    return ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_erai = load_erai()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CESM data\n",
    "This is just a CESM dataset that has native history files. These are monthly averages, and cover 5 years. \n",
    "\n",
    "I like to use the pathlib module to construct path objects, this could be done with strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = Path(\"/Volumes/project/amp/brianpm/vres/vres_L032\")\n",
    "ds_cesm = xr.open_mfdataset( stem.glob(\"*.h0.*.nc\"), combine='by_coords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal regrid\n",
    "\n",
    "We're going to do a simple bilinear remapping.\n",
    "\n",
    "Average ERAI in time (un-needed for this example, but just simplifies the data).\n",
    "\n",
    "Then use `xesmf` to create a regridding object. It uses the first argument to get the lat and lon coordinates of the source, and the second argument to get the lat and lon of the destination grid. Then it defines the type of interpolation (bilinear), the periodic keyward argument is set to True to use wraparound longitude, and `reuse_weights` allows us to re-use the weights file if we do multiple regrids.\n",
    "\n",
    "The result `regridder` is not the regridded data, it is the operator that performs regridding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_erai_climo = ds_erai.mean(dim='time')\n",
    "regridder = xe.Regridder(ds_erai_climo, dses[casenames[0]], 'bilinear', periodic=True, reuse_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out some example variable\n",
    "Xerai = ds_erai_climo['U']\n",
    "Xcesm = ds_cesm['U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('(horizontal) regrid step')\n",
    "xobs_orig = Xerai.compute()  # explicitly say to load into memory\n",
    "xobs = regridder(xobs_orig)  # xobs is the regridded data.\n",
    "print('regrid done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical regrid\n",
    "\n",
    "Now that we have put the ERA-Interim data on the CAM grid, we now want to regrid the CAM data to pressure levels. Here I provide a few functions that are used to regrid to pressure levels. \n",
    "\n",
    "In this approach, I have used numba as a just-in-time (jit) compiler. So the first time we call the `@jit` decorated funcitons, they will actually be compiled, which *should* make the function very fast (especially on subsequent calls when the compilation step is skipped). The main reason I think it is helpful here is because it allows us to simply do nested loops of a simple function (`interp`); this should make the function run as fast as a compiled numpy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get set up for pressure levels... \n",
    "\n",
    "def pres_from_hybrid(psfc, hya, hyb, p0=100000.):\n",
    "    # p = a(k)*p0 + b(k)*ps.\n",
    "    return hya*p0 + hyb*psfc\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def to_pres_4d(x_in, p, pnew):    \n",
    "    ntime, nlev_in, nlat, nlon = x_in.shape\n",
    "    nlev_out = len(pnew)\n",
    "    x_out = np.empty((ntime, nlev_out, nlat, nlon))\n",
    "    for time in range(ntime):\n",
    "        for lat in range(nlat):\n",
    "            for lon in range(nlon):\n",
    "                pin = p[time, :, lat, lon]\n",
    "                x_out[time, :, lat, lon] = np.interp(\n",
    "                    pnew, pin, x_in[time, :, lat, lon]\n",
    "                )\n",
    "    return x_out\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def to_pres_3d(x_in, p, pnew):\n",
    "    nlev_in, nlat, nlon = x_in.shape\n",
    "    nlev_out = len(pnew)\n",
    "    x_out = np.empty((nlev_out, nlat, nlon))\n",
    "    for lat in range(nlat):\n",
    "        for lon in range(nlon):\n",
    "            pin = p[:, lat, lon]\n",
    "            x_out[:, lat, lon] = np.interp(\n",
    "                pnew, pin, x_in[:, lat, lon]\n",
    "            )\n",
    "    return x_out\n",
    "\n",
    "\n",
    "# @jit(nopython=True)\n",
    "def to_pres(x_in, p, pnew):\n",
    "    s = x_in.shape\n",
    "    if len(s) == 4:\n",
    "        xout = to_pres_4d(x_in, p, pnew)\n",
    "    elif len(s) == 3:\n",
    "        xout = to_pres_3d(x_in, p, pnew)\n",
    "    return xout\n",
    "\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def shape_checker(x):\n",
    "    s = x.shape\n",
    "    l = len(s)\n",
    "    return l\n",
    "\n",
    "\n",
    "\n",
    "def to_pres_wrap(x_in, p_in, p_new):\n",
    "    # first unwrap into bare numpy\n",
    "    x_np = x_in.values\n",
    "    p_np = p_in.values\n",
    "    if isinstance(p_new, xr.DataArray):\n",
    "        print(\"Got dataarray for p, convert\")\n",
    "        p_new_np = p_new.values\n",
    "    else:\n",
    "        p_new_np = p_new\n",
    "    # interpolate to the new pressure levels\n",
    "    print(f\"[to_pres_wrap] Shapes being sent to to_pres: {x_np.shape} (length: {len(x_np.shape)}), {p_np.shape}, {p_new_np.shape}\")\n",
    "    x_plev = to_pres(x_np, p_np, p_new_np)  # numba should make this speedy.\n",
    "    # wrap back into DataArray\n",
    "    new_coords = dict()\n",
    "    for i in x_in.coords:\n",
    "        new_coords[i] = x_in[i]\n",
    "    new_coords['lev'] = p_new\n",
    "    return xr.DataArray(x_plev, coords=new_coords, dims=x_in.dims)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# info for pressure interp -- USE ERA-I PRESSURE LEVELS.\n",
    "pnew = ds_erai_climo['lev'].copy(deep=True) # Pa in the amwg netcdf files (n = 37, bottom to top)\n",
    "if max(pnew) > 2000:\n",
    "    print(\"ERAI lev must be in Pa\")\n",
    "else:\n",
    "    print(\"ERAI lev must be in hPa\")\n",
    "    pnew *= 100.\n",
    "    \n",
    "print(pnew.values)\n",
    "\n",
    "\n",
    "# pressure field on level midpoints\n",
    "pressure = pres_from_hybrid(ds_cesm['PS'], ds_cesm['hyam'], ds_cesm['hybm']).compute()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrid model to pressure levels:\n",
    "print(\"Start pressure level interpolation\")\n",
    "Xplev = to_pres_wrap(Xcesm, pressure, pnew)\n",
    "print(\"Finished pressure level interpolation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome\n",
    "\n",
    "We now should have ERA-Interim data regridded to the CAM horizontal grid, and the CAM data interpolated to the ERA-Interim pressure levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
